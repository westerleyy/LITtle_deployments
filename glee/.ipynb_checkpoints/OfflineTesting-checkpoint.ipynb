{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3defd4e",
   "metadata": {},
   "source": [
    "## Offline Testing  \n",
    "  \n",
    "Sandbox for the testing of the deployed app without using any Streamlit commands to allow for line-by-line debugging.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a3730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889576f3",
   "metadata": {},
   "source": [
    "**Lambda Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d7d3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantity_replacement(x):\n",
    "    quantity = x\n",
    "    try:\n",
    "        quantity = float(quantity)\n",
    "    except:\n",
    "        quantity = 0\n",
    "    return quantity\n",
    "\n",
    "def names_cleaning(x):\n",
    "    x = x.upper()\n",
    "    x = re.sub(r'\\([^)]*\\)', '', x)\n",
    "    sevenup_exception = re.search('7 UP|7UP', x)\n",
    "    if sevenup_exception:\n",
    "        x = x\n",
    "    else:\n",
    "        x = re.sub(\"[^a-zA-ZéÉíÍóÓúÚáÁ ]+\", \"\", x)\n",
    "        x = ' '.join( [w for w in x.split() if len(w)>2] )\n",
    "    return x\n",
    "\n",
    "# convert quantities to ml and gr\n",
    "def quantity_conversion(x):\n",
    "    thousand_multiplier = ['KG', 'K', 'KS', 'KGS', 'LTR', 'LT', 'LIT', 'LITRE', 'LITER']\n",
    "    ounce_multiplier = ['OZ']\n",
    "    alc_multiplier = ['CL']\n",
    "    cup_multiplier = ['CUP', 'CUPS']\n",
    "    spoon_multiplier = ['TBLS', 'TBSP']\n",
    "    soda_multiplier = ['CAN', 'BTL']\n",
    "    if x['Unit of Measurement'] in thousand_multiplier:\n",
    "        m = float(x['Quantity']) * 1000\n",
    "    elif x['Unit of Measurement'] in ounce_multiplier:\n",
    "        m = float(x['Quantity']) * 30\n",
    "    elif x['Unit of Measurement'] in alc_multiplier:\n",
    "        m = float(x['Quantity']) * 10\n",
    "    elif x['Unit of Measurement'] in cup_multiplier:\n",
    "        m = float(x['Quantity']) * 237\n",
    "    elif x['Unit of Measurement'] in spoon_multiplier:\n",
    "        m = float(x['Quantity']) * 15\n",
    "    elif x['Unit of Measurement'] in soda_multiplier:\n",
    "        m = float(x['Quantity']) * 300\n",
    "    else:\n",
    "        m = x['Quantity']\n",
    "    return m\n",
    "\n",
    "def multiplier_search(s):\n",
    "    m = 1\n",
    "    multiplier = re.search('[0-9]+[xX]| [0-9]+ [xX] | [xX] [0-9]+ | [xX][0-9+] ', s)\n",
    "    if multiplier:\n",
    "        interim = multiplier.group()\n",
    "        interim = re.sub('[^0-9]+', \"\", interim)\n",
    "        m = float(interim)\n",
    "    return m\n",
    "\n",
    "def unit_search(s):\n",
    "    m = 1000\n",
    "    s = re.sub(',', '.', s)\n",
    "    common_uoms = ['[0-9]+ML', ' [0-9]+ ML', \n",
    "                   ' [0-9]+ C', '[0-9]+C', '[0-9]+CS', '\\-[0-9.]+ ML', ' [0-9]+ CS',\n",
    "                   '[0-9.,]+KG', ' [0-9.,]+ KG', '\\-[0-9,.]+KG', '[0-9.,]+KGS', ' [0-9.,]+ KGS', '\\-[0-9.,]+KGS', '[0-9.,]+KS', ' [0-9.,]+ KS',\n",
    "                   '[0-9]+GR', ' [0-9]+ GR ', '[0-9]+ GR//', ' [0-9]+ GR//', '[0-9]+GMS', ' [0-9.]+ GMS', '[0-9 ]+GM', ' [0-9 ]+ GM', '[0-9]+G', ' [0-9]+ G ', '[0-9\\-]+GRAMS',  ' [0-9]+ GRAMS',                        \n",
    "                   '[0-9]+LB', ' [0-9]+ LB',\n",
    "                   '[0-9.]+CL', ' [0-9.]+ CL',\n",
    "                   '[0-9.]+LTR', ' [0-9.]+ LTR', '[0-9.]+LT','[0-9.]+L', ' [0-9.]+ LT',' [0-9.]+ L',\n",
    "                   '[0-9]+GAL', ' [0-9]+ GAL', '[0-9]+GL',\n",
    "                   '[0-9.]+OZ', ' [0-9.]+ OZ'\n",
    "                  ]\n",
    "    thousand_multiplier = ['KG', 'KGS', 'KS', 'L', 'LT', 'LTR']\n",
    "    gal_multiplier = ['GAL', 'GL']\n",
    "    ounce_multiplier = ['OZ']\n",
    "    lb_multiplier = ['LB']\n",
    "    alcohol = ['CL']\n",
    "    alcohol2 = ['C']\n",
    "    unit = re.search('|'.join(common_uoms), s)\n",
    "    if unit:\n",
    "        interim = unit.group()\n",
    "        interim = re.sub('[^0-9.]+', \"\", interim)\n",
    "        uom = re.sub('[^a-zA-Z]+', \"\", unit.group())\n",
    "        if interim != '.':\n",
    "            if uom in alcohol:\n",
    "                interim = float(interim) * 10\n",
    "            elif uom in thousand_multiplier:\n",
    "                interim = float(interim) * 1000\n",
    "            elif uom in gal_multiplier:\n",
    "                interim = float(interim) * 3780\n",
    "            elif uom in ounce_multiplier:\n",
    "                interim = float(interim) * 30\n",
    "            elif uom in lb_multiplier:\n",
    "                interim = float(interim) * 454\n",
    "            elif uom in alcohol2:\n",
    "                interim = float(interim) * 10\n",
    "            m = float(interim)\n",
    "            if m == 0:\n",
    "                m = 1000\n",
    "    return m\n",
    "\n",
    "def soda_multiplier(t):\n",
    "    sec_multiplier = 1\n",
    "    soda_identifier = ' CS'\n",
    "    soda_search = re.search(soda_identifier, t)\n",
    "    if soda_search:\n",
    "        sec_multiplier = 24\n",
    "    return sec_multiplier  \n",
    "\n",
    "def drinks_unit_price_multiplier(d):\n",
    "    multiplier = d['Unit Price']\n",
    "    if d['Upload Time'] < '2021-11-22' and (d['Category'] == 'Alcoholic Beverage' or d['Category'] == 'Beverage - Alcohol' or d['Category'] == 'Alcohol Beverage' or d['Category']== 'Alc Beverage'):\n",
    "        multiplier = 1.3 * d['Unit Price']\n",
    "    elif d['Upload Time'] < '2021-11-22' and (d['Category'] == 'Non Alcoholic Beverage' or d['Category'] == 'Beverage - Non Alcohol' or d['Category'] == 'Beverage - Soft' or d['Category'] == 'Beverage  - Soft' or d['Category'] == 'N-Alc Beverage'):\n",
    "        multiplier_exclusion = re.search('JUICE|SYRUP|AQU|SPARKLING', d['Product Name'])\n",
    "        if multiplier_exclusion:\n",
    "            multiplier = 1 * d['Unit Price']\n",
    "        else:\n",
    "            multiplier = 1.5 * d['Unit Price']\n",
    "    return multiplier  \n",
    "\n",
    "def unit_price_adjustment(x):\n",
    "    x = re.sub(r'AED ', '', x)\n",
    "    x = re.sub(r',', '', x)\n",
    "    x = float(x)\n",
    "    return x\n",
    "\n",
    "def load_transformer():\n",
    "    sbert_model = SentenceTransformer('stsb-mpnet-base-v2')\n",
    "    return sbert_model\n",
    "\n",
    "def recipe_item_embeddings_fn(unique_recipe_items):\n",
    "    recipe_item_embeddings = sbert_model.encode(unique_recipe_items, convert_to_tensor = True)\n",
    "    return recipe_item_embeddings\n",
    "\n",
    "def stock_in_embeddings_fn(recipe_ingredients_list):\n",
    "    stock_in_embeddings = sbert_model.encode(recipe_ingredients_list, convert_to_tensor = True)\n",
    "    return stock_in_embeddings\n",
    "\n",
    "def unit_dict_accretion(x):\n",
    "    uploaded_unit = x['Corrected Unit Size']\n",
    "    if uploaded_unit == 0:\n",
    "        uploaded_unit = x['Unit Size']\n",
    "    return uploaded_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2097f6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init. sbert\n",
    "sbert_model = load_transformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299bf1f0",
   "metadata": {},
   "source": [
    "**Handling POS Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efd68a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesch\\miniconda3\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    " # import pos data\n",
    "pos_sheet_df = pd.read_excel(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\output\\dec21_reporting\\Farm2Table\\POS.xlsx', skiprows = 6, sheet_name = \"Revenue per article\")\n",
    "pos_sheet_df = pos_sheet_df.dropna(how = 'all')\n",
    "all_pos_cleaned = pos_sheet_df.loc[(pos_sheet_df['Article']!= 'Total'),].copy()\n",
    "all_pos_cleaned['Article'] = all_pos_cleaned.loc[:,'Article'].str.upper()\n",
    "\n",
    "# total revenue\n",
    "all_pos_cleaned = all_pos_cleaned.rename(columns = {'Net revenue': 'Revenue'})\n",
    "all_revenue = round(all_pos_cleaned['Revenue'].sum(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbea6c6",
   "metadata": {},
   "source": [
    "**Handling Recipe Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a0ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import recipe data\n",
    "recipe_sheet_df = pd.read_excel(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\output\\nov21_reporting\\Scarpetta\\Recipe.xlsx', sheet_name = 'Reformatted')\n",
    "recipe_sheet_df = recipe_sheet_df.dropna(how = 'all')\n",
    "recipe_sheet_df = recipe_sheet_df.dropna(subset = ['Food Item (As per POS system)'])\n",
    "recipe_sheet_df = recipe_sheet_df.dropna(subset = ['Ingredient Ordered (if known)'])\n",
    "recipe_sheet_df['Food Item (As per POS system)'] = recipe_sheet_df['Food Item (As per POS system)'].apply(lambda x: x.rstrip())\n",
    "\n",
    "# ensure servings column is an int, upper case all and clean the ingredient names\n",
    "# check and replace quantity column to make sure it is an integer\n",
    "\n",
    "recipe_sheet_df['Quantity'] = recipe_sheet_df.Quantity.apply(lambda x: quantity_replacement(str(x)))\n",
    "    \n",
    "recipe_sheet_df = recipe_sheet_df.assign(\n",
    "    Servings = lambda x: x.Servings.astype(int),\n",
    "    Quantity = lambda y: y.Quantity.astype(float)/y.Servings\n",
    ")\n",
    "\n",
    "# upper case all and clean the ingredient names\n",
    "recipe_sheet_df.replace(np.inf, 0, inplace = True)\n",
    "recipe_sheet_df['Food Item (As per POS system)'] = recipe_sheet_df.loc[:,'Food Item (As per POS system)'].str.upper()\n",
    "recipe_sheet_df['Unit of Measurement'] = recipe_sheet_df.loc[:,'Unit of Measurement'].str.upper()        \n",
    "recipe_sheet_df['Ingredient'] = recipe_sheet_df['Ingredient Ordered (if known)'].apply(lambda x: names_cleaning(str(x))) \n",
    "\n",
    "## rename new quantity column accordingly\n",
    "recipe_sheet_df['NewQuantity'] = recipe_sheet_df.apply(quantity_conversion, axis = 1)\n",
    "recipe_sheet_df.drop('Quantity', axis = 1, inplace = True)\n",
    "recipe_sheet_df.rename(columns = {'NewQuantity': 'Quantity'}, inplace = True)\n",
    "    \n",
    "# get list of ingredients\n",
    "recipe_ingredients_list = recipe_sheet_df['Ingredient'].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd423a7e",
   "metadata": {},
   "source": [
    "**POS to Recipe Items Ingredients Crosswalk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d186d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get list of food items in recipe sheet\n",
    "unique_recipe_items = recipe_sheet_df['Food Item (As per POS system)'].dropna().drop_duplicates().tolist()\n",
    "\n",
    "# initialize embeddings\n",
    "recipe_item_embeddings = recipe_item_embeddings_fn(unique_recipe_items)\n",
    "\n",
    "# get unique menu items from POS\n",
    "pos_items = all_pos_cleaned['Article'].dropna().drop_duplicates().tolist()\n",
    "    \n",
    "# get a list of most similar item on the menu from recipe and pos sheets\n",
    "most_similar = []\n",
    "for item in pos_items:\n",
    "    query_embedding = sbert_model.encode(item, convert_to_tensor = True)\n",
    "    cos_score = util.pytorch_cos_sim(query_embedding, recipe_item_embeddings)[0]\n",
    "    best_match = torch.topk(cos_score, k = 1)\n",
    "    for idx in best_match[1]:\n",
    "        most_similar.append(unique_recipe_items[idx])\n",
    "\n",
    "del query_embedding\n",
    "    \n",
    "# stacking into a df\n",
    "matched_recipe_pos_df = pd.DataFrame({\n",
    "    'POS Items': pos_items,\n",
    "    'Recipe Items': most_similar\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ece0a6b",
   "metadata": {},
   "source": [
    "**Import Invoice Details Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae03e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stock-in data\n",
    "stock_in = pd.read_csv(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\output\\dec21_reporting\\Farm2Table\\InvoiceDetails_Amalgamated.csv', encoding = 'utf-8')\n",
    "\n",
    "def unit_price_adjustment(x):\n",
    "    x = re.sub(r'AED ', '', x)\n",
    "    x = re.sub(r',', '', x)\n",
    "    x = float(x)\n",
    "    return x\n",
    "\n",
    "start_date = '2021-12-01'\n",
    "end_date = '2021-12-31'\n",
    "\n",
    "\n",
    "df = stock_in.loc[(stock_in['Invoice Date'] >= start_date),].copy()\n",
    "df = df.loc[(df['Invoice Date'] <= end_date),]\n",
    "\n",
    "df['Subtotal'] = df['Subtotal'].apply(lambda x: unit_price_adjustment(str(x)))  \n",
    "\n",
    "print(df['Subtotal'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6047076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stock-in data\n",
    "stock_in = pd.read_csv(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\output\\dec21_reporting\\Farm2Table\\InvoiceDetails_Amalgamated.csv', encoding = 'utf-8')\n",
    "\n",
    "# remove nas\n",
    "stock_in = stock_in.dropna()\n",
    "\n",
    "# remove trailing white spaces\n",
    "stock_in['Category'] = stock_in['Category'].apply(lambda x: x.rstrip())\n",
    "\n",
    "# remove those categories to be excluded\n",
    "category_exclusion_split = ['Printing & Stationary', 'Printing and Stationery Supplies', 'Tax Adjustment', 'CAPEX', 'Other', 'Cleaning', 'Cleaning Supplies', 'Kitchen Supplies', 'Discount', 'Guest Supplies', 'Rounding', 'General Supplies', \n",
    "                            'Packaging',  'Bar Expenses','Operating Supplies General', 'HR', 'Payroll', 'Cleaning & Chemical', 'Utilities', 'Music & entertainment', 'Payroll & Related Expenses', 'PR & Marketing', 'Payroll Provision (Guest Chefs)',\n",
    "                            'Transport', 'Accommodation & Air Tickets', 'OS&E - Kitchen', 'OS&E - FOH', 'Supplies Kitchen', 'Supplies Others', 'Supplies Cleaning', 'Provision', 'Accommodation', 'Crockery', 'Small Equipment', \n",
    "                            'Departmental Supplies', 'Cleaning', 'Disposables and Chemicals', 'Payroll and HR related',  'Staff Training', 'Paper Supplies', 'Uniforms', 'Passage', 'Travel Other', 'Miscellaneous Expenses', \n",
    "                            'VisaVisa MedicalsMedical Lev', 'Linen', 'Equipment Hire', 'Fuel',  'Meals', 'Marketing Expense', 'Managment Fee', 'Legal / Licenses', 'Pre-Opening Printing and Stationery Supplies', 'Pre-Opening - Kitchenware', \n",
    "                            'Pre-Opening - Payroll / HR Related', 'Pre-Opening - Accommodation & Air Tickets', 'Pre-Opening - Linen & Uniform', 'Pre-Opening - Legal / Licenses', 'Pre-Opening-PR & Marketing', 'Pre-Opening - IT & Technology', \n",
    "                            'Pre-Opening - China/Glass/Silver', 'Pre-Opening - Staff Meal', 'Pre-Opening Expenses', 'Pre-Opening Operating Supplies', 'Pre-Opening Training', 'Pre-Opening-PR & Marketing', 'Pre-Opening Music and Entertain. Expenses',\n",
    "                            'OE-China', 'OE-Uniform', 'OE-Others', 'OE-Security/ Cleaning', 'OE-Kitchen supplies',  'OE-Music & entertainment', 'OE-Provision', 'FC-Bank Charges', 'OE - Admin - Supplies', 'OE-Glasswares', 'OE-Provision', \n",
    "                            'OE-Laundry', 'OE-Supply cleaning', 'OE-Packaging', 'OE-Guest supplies', 'OE-Printing & stationary', 'OE - ADMIN - Printing', 'OE-Others', 'FC-PR & Marketing', 'OE - Admin - Transport', 'FC-IT & Technology',\n",
    "                            'OE-Bar Expenses', 'OE-Admin - Meal Allocation', 'Task force']\n",
    "category_exclusion_split = [x.rstrip() for x in category_exclusion_split]\n",
    "exclusions = ~stock_in.Category.isin(category_exclusion_split)\n",
    "stock_in = stock_in[exclusions]\n",
    "\n",
    "# remove trailing white spaces, excessive whitespaces and other stuff\n",
    "stock_in['Product Name'] = stock_in['Product Name'].apply(lambda x: x.rstrip())\n",
    "\n",
    "# extracting uoms and unit sizes\n",
    "# need to convert everything from kg to g, and ltr to ml\n",
    "common_uoms = ['GM', 'KG', '[0-9]+GR', ' GR ', 'GMS', 'KGS', '[0-9]+G', '[0-9.]+ GR//', \n",
    "               'GRAMS', ' GR ', ' G ', '[0-9.]+ GR', '[0-9.]+KS',  '[0-9.]+ GMS', '[0-9]+ KGS', \n",
    "               '[0-9]+LB', ' [0-9]+ LB', '[A-Z0-9/-]+KGS',\n",
    "               'LTR', 'ML','[0-9]+CL', 'LT', '[0-9]+L',  '[0-9]+ML', ' [0-9.]+C', '[0-9.]+ CL', \n",
    "               '[0-9.]+ CS', '[0-9]+GAL', ' [0-9]+ GAL', '[0-9]+OZ', ' [0-9]+ OZ' ]\n",
    "\n",
    "common_uoms_equivalent = ['GR', 'GR', 'GR', 'GR', 'GR', 'GR', 'GR', 'GR', 'GR', 'GR', 'GR', 'GR', \n",
    "                          'GR', 'GR', 'GR', 'GR', 'GR', 'GR',\n",
    "                          'ML', 'ML', 'ML', 'ML', 'ML', 'ML', 'ML', 'ML', 'ML', 'ML', 'ML', 'ML', \n",
    "                          'ML']\n",
    "\n",
    "for uom in range(len(common_uoms)):\n",
    "    stock_in.loc[stock_in['Product Name'].str.contains(common_uoms[uom]), 'Unit of Measurement'] = common_uoms_equivalent[uom]\n",
    "\n",
    "stock_in['Unit'] = stock_in['Unit'].apply(lambda x: re.sub(\"KGS|KG\", \"GR\", x))\n",
    "\n",
    "\n",
    "# adjust unit price column\n",
    "# look for multipliers, unit size, and apply\n",
    "stock_in['Unit Price'] = stock_in['Unit Price'].apply(lambda x: unit_price_adjustment(str(x)))    \n",
    "stock_in['Unit Price'] = stock_in.apply(drinks_unit_price_multiplier, axis = 1)\n",
    "stock_in['multiplier'] = stock_in['Product Name'].apply(lambda x: multiplier_search(x))\n",
    "stock_in['unit_size'] = stock_in['Product Name'].apply(lambda x: unit_search(x))\n",
    "stock_in['soda_multiplier'] = stock_in['Product Name'].apply(lambda x: soda_multiplier(x))\n",
    "stock_in = stock_in.assign(\n",
    "   unit_size = lambda x: x.unit_size * x.multiplier * x.soda_multiplier\n",
    ")\n",
    "stock_in = stock_in.rename(columns = {'unit_size':'Unit Size'})\n",
    "stock_in.drop(['multiplier', 'soda_multiplier'], axis = 1, inplace = True)    \n",
    "\n",
    "# agg orders\n",
    "stock_in_agg = stock_in[['Product Name', 'Qty', 'Unit', 'Unit Size',  'Unit Price']].copy()\n",
    "stock_in_agg['Est Total Cost'] = stock_in_agg['Qty'] * stock_in_agg['Unit Price']\n",
    "stock_in_agg.drop('Unit Price', axis = 1, inplace = True)\n",
    "stock_in_agg = stock_in_agg.groupby(['Product Name', 'Unit', 'Unit Size']).sum()\n",
    "stock_in_agg = stock_in_agg.reset_index()\n",
    "\n",
    "# remove rows with empty values\n",
    "stock_in_agg = stock_in_agg.loc[stock_in_agg['Product Name'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7a3c5a",
   "metadata": {},
   "source": [
    "**Correct Unit Size Dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d40d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_invoice_unit_sizes_df = pd.read_csv(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\output\\dec21_reporting\\Baron\\Output\\Round 1\\invoice_details_unit_size_amended.csv', encoding = 'utf-8')\n",
    "matched_invoice_unit_sizes_df = matched_invoice_unit_sizes_df.fillna(0)\n",
    "\n",
    "# replace unit size \n",
    "matched_invoice_unit_sizes_df = matched_invoice_unit_sizes_df.rename(columns = {'Unit Size': 'Corrected Unit Size'})\n",
    "stock_in_agg = stock_in_agg.merge(matched_invoice_unit_sizes_df, on = 'Product Name', how = 'left')\n",
    "stock_in_agg['Corrected Unit Size'] = stock_in_agg['Corrected Unit Size'].fillna(0)\n",
    "stock_in_agg['Accreted Unit Size'] = stock_in_agg.apply(unit_dict_accretion, axis = 1)\n",
    "stock_in_agg.drop(['Unit Size', 'Corrected Unit Size'], axis = 1, inplace = True)\n",
    "stock_in_agg = stock_in_agg.rename(columns = {'Accreted Unit Size': 'Unit Size'})\n",
    "stock_in_agg_margin = stock_in_agg.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2d4664",
   "metadata": {},
   "source": [
    "Getting Unit Cost based on Unit Size Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566fdc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# continuation of above REGARDLESS of presence of corrected stock in data\n",
    "stock_in_agg_margin['unit_cost'] = stock_in_agg_margin['Est Total Cost'] / (stock_in_agg_margin['Unit Size'] * stock_in_agg_margin['Qty'])\n",
    "\n",
    "stock_in_agg_margin['productname_cleaned'] = stock_in_agg_margin['Product Name'].apply(lambda x: names_cleaning(str(x))) \n",
    "\n",
    "# creating a dictionary of product names\n",
    "product_name_dictionary = stock_in_agg_margin[['productname_cleaned', 'Product Name', 'Unit Size']].copy()\n",
    "product_name_dictionary = product_name_dictionary.drop_duplicates()\n",
    "unique_product_names = product_name_dictionary['productname_cleaned'].drop_duplicates().tolist()\n",
    "\n",
    "# product name and unit size dictionary to be exported\n",
    "product_name_dictionary2 = product_name_dictionary[['Product Name', 'Unit Size']]\n",
    "\n",
    "# total cost\n",
    "total_stock_in_cost = stock_in_agg_margin['Est Total Cost'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb78c5c",
   "metadata": {},
   "source": [
    "**Invoice Details to Recipe Ingredients Stock-In**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc50a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init. embeddings for invoice details\n",
    "stock_in_embeddings = stock_in_embeddings_fn(recipe_ingredients_list)\n",
    "\n",
    "# get a list of most similar item stocked from recipe and stock-in sheets\n",
    "most_similar = []\n",
    "for item in unique_product_names:\n",
    "    query_embedding = sbert_model.encode(item, convert_to_tensor = True)\n",
    "    cos_score = util.pytorch_cos_sim(query_embedding, stock_in_embeddings)[0]\n",
    "    best_match = torch.topk(cos_score, k = 1)\n",
    "    for idx in best_match[1]:\n",
    "        most_similar.append(recipe_ingredients_list[idx])\n",
    "\n",
    "del query_embedding\n",
    "\n",
    "# stacking into a df\n",
    "matched_ingredients_stock_in_df = pd.DataFrame({\n",
    "    'productname_cleaned': unique_product_names,\n",
    "    'Ingredient': most_similar\n",
    "    })\n",
    "\n",
    "matched_ingredients_stock_in_df = matched_ingredients_stock_in_df.merge(product_name_dictionary)\n",
    "matched_ingredients_stock_in_df.drop('productname_cleaned', axis = 1, inplace = True)\n",
    "matched_ingredients_stock_in_df = matched_ingredients_stock_in_df[['Product Name', 'Ingredient']]\n",
    "\n",
    "# bringing in amended crosswalks\n",
    "matched_ingredients_stock_in_amended_df = pd.read_csv(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\output\\nov21_reporting\\Adrift\\stock_in_ingredients_xwalk_amended.csv', encoding = 'utf-8')\n",
    "matched_recipe_pos_amended_df = pd.read_csv(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\output\\nov21_reporting\\Adrift\\recipe_pos_amended.csv', encoding = 'utf-8')\n",
    "\n",
    "# appending old crosswalk to new\n",
    "matched_ingredients_list = matched_ingredients_stock_in_amended_df['Product Name'].drop_duplicates().tolist()\n",
    "new_items = matched_ingredients_stock_in_df.loc[~matched_ingredients_stock_in_df['Product Name'].isin(matched_ingredients_list),]\n",
    "matched_ingredients_stock_in_amended_df = pd.concat([matched_ingredients_stock_in_amended_df, new_items])\n",
    "matched_ingredients_stock_in_amended_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "matched_pos_list = matched_recipe_pos_amended_df['POS Items'].drop_duplicates().tolist()\n",
    "new_pos_items = matched_recipe_pos_df.loc[~matched_recipe_pos_df['POS Items'].isin(matched_pos_list),]\n",
    "matched_recipe_pos_amended_df = pd.concat([matched_recipe_pos_amended_df, new_pos_items])\n",
    "matched_recipe_pos_amended_df.reset_index(inplace = True, drop = True)\n",
    "matched_recipe_pos_amended_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6407758",
   "metadata": {},
   "source": [
    "**POS to Recipe Stock-In to Invoice Details**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d506352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out items ordered during the period \n",
    "pos_sheet_cleaned_ordered = all_pos_cleaned[['Article', 'Number of articles']].copy()\n",
    "pos_sheet_cleaned_ordered['Article'] = pos_sheet_cleaned_ordered['Article'].str.upper()\n",
    "pos_sheet_cleaned_ordered = pos_sheet_cleaned_ordered.merge(matched_recipe_pos_amended_df, left_on = 'Article', right_on = 'POS Items')\n",
    "pos_sheet_cleaned_ordered['Recipe Items'] = pos_sheet_cleaned_ordered['Recipe Items'].str.upper()\n",
    "pos_sheet_cleaned_ordered = pos_sheet_cleaned_ordered[['Article', 'Number of articles', 'Recipe Items']]\n",
    "\n",
    "# ingredient stock in crosswalk\n",
    "ingredient_stockin_recipe_qc = matched_ingredients_stock_in_amended_df.merge(recipe_sheet_df[['Ingredient', 'Ingredient Ordered (if known)']].drop_duplicates(),\n",
    "                                                                             on = 'Ingredient')\n",
    "\n",
    "# merge with recipes df to get the recipes for which we have a crosswalk match\n",
    "recipe_ordered = recipe_sheet_df.merge(pos_sheet_cleaned_ordered,\n",
    "                                       left_on = 'Food Item (As per POS system)',\n",
    "                                       right_on = 'Recipe Items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3c623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_ordered[['Food Item (As per POS system)']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81094411",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_sheet_df[['Food Item (As per POS system)']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sheet_cleaned_ordered[['Recipe Items']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e638a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos_sheet_cleaned_ordered.loc[~pos_sheet_cleaned_ordered['Recipe Items'].isin(recipe_ordered['Food Item (As per POS system)'].drop_duplicates().tolist()), 'Recipe Items'].drop_duplicates().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b188c974",
   "metadata": {},
   "source": [
    "**Unmatched Items**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f30dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate quantity consumed by min serving size\n",
    "## ceiling\n",
    "recipe_ordered['Quantity Consumed'] = recipe_ordered['Number of articles']*recipe_ordered['Quantity']\n",
    "\n",
    "\n",
    "# get items that cannot be matched to recipes\n",
    "unmatched = matched_ingredients_stock_in_amended_df.loc[matched_ingredients_stock_in_amended_df.Ingredient.isna(),]\n",
    "unmatched = unmatched.merge(stock_in_agg_margin)\n",
    "unmatched = unmatched[['Product Name', 'Unit', 'Qty', 'Est Total Cost']]\n",
    "unmatched = unmatched.drop_duplicates()\n",
    "\n",
    "\n",
    "# get pos items that cannot be matched properly\n",
    "unmatched_pos = matched_recipe_pos_amended_df.loc[matched_recipe_pos_amended_df['Recipe Items'].isna(), 'POS Items']\n",
    "unmatched_pos = pd.DataFrame(unmatched_pos)\n",
    "unmatched_pos = unmatched_pos.rename(columns = {'POS Items': 'Article'})\n",
    "unmatched_pos = unmatched_pos.merge(all_pos_cleaned[['Article', 'Number of articles', 'Revenue']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1eb65f",
   "metadata": {},
   "source": [
    "**Margin Calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14a9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate margins\n",
    "cost_calculation = recipe_ordered[['Food Item (As per POS system)', 'Ingredient', 'Quantity']].copy()\n",
    "cost_calculation = cost_calculation.merge(matched_ingredients_stock_in_amended_df, on = 'Ingredient')\n",
    "cost_calculation = cost_calculation.merge(stock_in_agg_margin[['Product Name', 'unit_cost']], on = 'Product Name')\n",
    "cost_calculation.replace(np.inf, 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd75565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cost \n",
    "cost_calculation = cost_calculation.assign(\n",
    "    constituent_cost = lambda x: x['Quantity'] * x['unit_cost']\n",
    "    )\n",
    "\n",
    "# averaging out the cost when there is more than one possible identical ingredient\n",
    "summarized_cost_calculation = cost_calculation.groupby(['Food Item (As per POS system)', 'Ingredient', 'Quantity']).agg(\n",
    "    mean_constituent_cost=('constituent_cost', 'mean'))\n",
    "\n",
    "summarized_cost_calculation = summarized_cost_calculation.reset_index()\n",
    "summarized_cost_calculation = summarized_cost_calculation.drop_duplicates()\n",
    "\n",
    "# obtaining COGS\n",
    "cost_of_goods_sold = summarized_cost_calculation.groupby('Food Item (As per POS system)').sum()\n",
    "\n",
    "## crosswalk to connect to the POS system\n",
    "cost_of_goods_sold = cost_of_goods_sold.merge(matched_recipe_pos_amended_df, \n",
    "                                              left_on = 'Food Item (As per POS system)', \n",
    "                                              right_on = 'Recipe Items')\n",
    "\n",
    "cost_of_goods_sold = cost_of_goods_sold.merge(all_pos_cleaned[['Article', 'Revenue']],\n",
    "                                              left_on = 'POS Items',\n",
    "                                              right_on = 'Article')\n",
    "\n",
    "summarized_cost_calculation = summarized_cost_calculation.rename(columns = {\n",
    "    'mean_constituent_cost': 'Cost of Ingredient'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4bedc2",
   "metadata": {},
   "source": [
    "### Unmatched POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "912ba8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesch\\AppData\\Local\\Temp/ipykernel_25100/2696284275.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unmatched_inventory_drinks['Cost'] = unmatched_inventory_drinks['Cost'].apply(lambda x: unit_price_adjustment(str(x)))\n"
     ]
    }
   ],
   "source": [
    "unmatched_pos = pd.read_csv(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\output\\jan22_reporting\\National\\Output\\Round 2\\unmatched_pos_articles.csv', encoding = 'utf-8')\n",
    "unmatched_inventory = pd.read_csv(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\output\\jan22_reporting\\National\\Output\\Round 2\\estimated_unused_orders.csv', encoding = 'utf-8')\n",
    "stock_in = pd.read_csv(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\output\\jan22_reporting\\National\\InvoiceDetails_amended.csv', encoding = 'utf-8')\n",
    "unit_sizes = pd.read_csv(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\output\\jan22_reporting\\National\\Output\\Round 2\\invoice_details_unit_size.csv', encoding = 'utf-8')\n",
    "\n",
    "# get drinks categories\n",
    "drinks_category = ['Groceries', 'Bakery & Pastry Products', 'Alcoholic Beverage', 'Beverage - Alcohol', 'Alcohol Beverage', 'Alc Beverage', 'Non Alcoholic Beverage', 'Beverage - Non Alcohol', 'Beverage - Soft', 'Beverage  - Soft', 'N-Alc Beverage', 'Food']\n",
    "category_exclusion_split = ['Printing & Stationary', 'Printing and Stationery Supplies', 'Tax Adjustment', 'CAPEX', 'Other', 'Cleaning', 'Cleaning Supplies', 'Kitchen Supplies', 'Discount', 'Guest Supplies', 'Rounding', 'General Supplies', \n",
    "                            'Packaging',  'Bar Expenses','Operating Supplies General', 'HR', 'Payroll', 'Cleaning & Chemical', 'Utilities', 'Music & entertainment', 'Payroll & Related Expenses', 'PR & Marketing', 'Payroll Provision (Guest Chefs)',\n",
    "                            'Transport', 'Accommodation & Air Tickets', 'OS&E - Kitchen', 'OS&E - FOH', 'Supplies Kitchen', 'Supplies Others', 'Supplies Cleaning', 'Provision', 'Accommodation', 'Crockery', 'Small Equipment', \n",
    "                            'Departmental Supplies', 'Cleaning', 'Disposables and Chemicals', 'Payroll and HR related',  'Staff Training', 'Paper Supplies', 'Uniforms', 'Passage', 'Travel Other', 'Miscellaneous Expenses', \n",
    "                            'VisaVisa MedicalsMedical Lev', 'Linen', 'Equipment Hire', 'Fuel',  'Meals', 'Marketing Expense', 'Managment Fee', 'Legal / Licenses', 'Pre-Opening Printing and Stationery Supplies', 'Pre-Opening - Kitchenware', \n",
    "                            'Pre-Opening - Payroll / HR Related', 'Pre-Opening - Accommodation & Air Tickets', 'Pre-Opening - Linen & Uniform', 'Pre-Opening - Legal / Licenses', 'Pre-Opening-PR & Marketing', 'Pre-Opening - IT & Technology', \n",
    "                            'Pre-Opening - China/Glass/Silver', 'Pre-Opening - Staff Meal', 'Pre-Opening Expenses', 'Pre-Opening Operating Supplies', 'Pre-Opening Training', 'Pre-Opening-PR & Marketing', 'Pre-Opening Music and Entertain. Expenses',\n",
    "                            'OE-China', 'OE-Uniform', 'OE-Others', 'OE-Security/ Cleaning', 'OE-Kitchen supplies',  'OE-Music & entertainment', 'OE-Provision', 'FC-Bank Charges', 'OE - Admin - Supplies', 'OE-Glasswares', 'OE-Provision', \n",
    "                            'OE-Laundry', 'OE-Supply cleaning', 'OE-Packaging', 'OE-Guest supplies', 'OE-Printing & stationary', 'OE - ADMIN - Printing', 'OE-Others', 'FC-PR & Marketing', 'OE - Admin - Transport', 'FC-IT & Technology',\n",
    "                            'OE-Bar Expenses', 'OE-Admin - Meal Allocation', 'Task force']\n",
    "# filter for drinks ordered\n",
    "stock_in_drinks = stock_in.loc[~stock_in['Category'].isin(category_exclusion_split), 'Product Name'].drop_duplicates().tolist()\n",
    "\n",
    "# filter for drinks that are in unmatched inventory\n",
    "unmatched_inventory_drinks = unmatched_inventory.loc[unmatched_inventory['Product Name'].isin(stock_in_drinks),]\n",
    "unmatched_inventory_drinks['Cost'] = unmatched_inventory_drinks['Cost'].apply(lambda x: unit_price_adjustment(str(x)))\n",
    "unmatched_inventory_drinks = unmatched_inventory_drinks.groupby('Product Name').sum()\n",
    "unmatched_inventory_drinks.reset_index(inplace = True)\n",
    "\n",
    "# embeddings fn\n",
    "def stock_in_embeddings_fn(recipe_ingredients_list):\n",
    "    stock_in_embeddings = sbert_model.encode(recipe_ingredients_list, convert_to_tensor = True)\n",
    "    return stock_in_embeddings\n",
    "\n",
    "# get unmatched pos articles\n",
    "unmatched_pos_articles = unmatched_pos.Article.tolist()\n",
    "unique_product_names = unmatched_inventory_drinks['Product Name'].drop_duplicates().tolist()\n",
    "\n",
    "# init embeddings\n",
    "stock_in_embeddings = stock_in_embeddings_fn(unique_product_names)\n",
    "\n",
    "most_similar = []\n",
    "cos = []\n",
    "for item in unmatched_pos_articles:\n",
    "    query_embedding = sbert_model.encode(item, convert_to_tensor = True)\n",
    "    cos_score = util.pytorch_cos_sim(query_embedding, stock_in_embeddings)[0]\n",
    "    best_match = torch.topk(cos_score, k = 1)\n",
    "    for idx in best_match[1]:\n",
    "        most_similar.append(unique_product_names[idx])\n",
    "    for idx in best_match[0]:\n",
    "        cos.append(idx)\n",
    "        \n",
    "del query_embedding\n",
    "\n",
    "# stacking into a df\n",
    "matched_remainder_df = pd.DataFrame({\n",
    "    'Unmatched Article': unmatched_pos_articles,\n",
    "    'Most Similar Stock In': most_similar\n",
    "    })\n",
    "\n",
    "matched_remainder_df.to_csv(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\output\\jan22_reporting\\National\\Output\\Round 2\\unmatched_direct_match.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1fc9573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wesch\\miniconda3\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "# import pos data\n",
    "pos_sheet_df = pd.read_excel(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\output\\jan22_reporting\\National\\POS.xlsx', skiprows = 6, sheet_name = \"Revenue per article\")\n",
    "pos_sheet_df = pos_sheet_df.dropna(how = 'all')\n",
    "all_pos_cleaned = pos_sheet_df.loc[(pos_sheet_df['Article']!= 'Total'),].copy()\n",
    "all_pos_cleaned['Article'] = all_pos_cleaned.loc[:,'Article'].str.upper()\n",
    "\n",
    "# total revenue\n",
    "all_pos_cleaned = all_pos_cleaned.rename(columns = {'Net revenue': 'Revenue'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6651f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_remainder_amended_df = pd.read_csv(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\output\\jan22_reporting\\National\\Output\\Round 2\\unmatched_direct_match_amended.csv')\n",
    "matched_remainder_amended_df = matched_remainder_amended_df.drop_duplicates()\n",
    "\n",
    "\n",
    "# match on amalgamated stock in because it is easier to do the prelim match on unmatched\n",
    "## and then expand to include the full range because of wine sold by the glass not being properly accounted in recipe\n",
    "\n",
    "stock_in_drinks_expanded = stock_in.loc[~stock_in['Category'].isin(category_exclusion_split), ['Product Name', 'Qty', 'Subtotal', 'Unit']].copy()\n",
    "stock_in_drinks_expanded['Subtotal'] = stock_in_drinks_expanded['Subtotal'].apply(lambda x: unit_price_adjustment(str(x)))\n",
    "stock_in_drinks_expanded = stock_in_drinks_expanded.groupby(['Product Name', 'Unit']).sum()\n",
    "stock_in_drinks_expanded.reset_index(inplace = True)\n",
    "\n",
    "# filter for records that are from Farm2Table\n",
    "## Farm2Table records need to be separated into those with ready costing, and those without\n",
    "try:\n",
    "    matched_remainder_amended_df_f = matched_remainder_amended_df.loc[matched_remainder_amended_df['ReadyCosting']=='F', ].copy()\n",
    "    matched_remainder_amended_df_f = matched_remainder_amended_df_f.merge(stock_in_drinks_expanded, left_on = \"Most Similar Stock In\", right_on = \"Product Name\")\n",
    "    matched_remainder_amended_df_f.drop(['ReadyCosting', 'Product Name'], axis = 1, inplace = True)\n",
    "    \n",
    "    ready_costing = pd.read_excel(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\output\\dec21_reporting\\Farm2Table\\Recipe.xlsx', sheet_name = 'rest of items ready costing')\n",
    "    matched_remainder_amended_df_t = matched_remainder_amended_df.loc[matched_remainder_amended_df['ReadyCosting']=='T', ].copy()\n",
    "    matched_remainder_amended_df_t = matched_remainder_amended_df_t.merge(ready_costing[['Food Item (As per POS system)', 'Recipe AED Cost']], left_on = 'Most Similar Stock In', right_on = 'Food Item (As per POS system)')\n",
    "    matched_remainder_amended_df_t.drop(['Food Item (As per POS system)', 'ReadyCosting'], axis = 1, inplace = True)\n",
    "    matched_remainder_amended_df_t.rename(columns = {'Recipe AED Cost': 'Subtotal'}, inplace = True)\n",
    "    matched_remainder_amended_df_t['Subtotal'] = matched_remainder_amended_df_t['Subtotal'].apply(lambda x: round(x, 2))\n",
    "    matched_remainder_amended_df_t['Unit'] = \"\"\n",
    "    matched_remainder_amended_df_t['Qty'] = \"\"\n",
    "    matched_remainder_amended_df_t = matched_remainder_amended_df_t[['Unmatched Article', 'Most Similar Stock In', 'Unit', 'Qty', 'Subtotal']].copy()\n",
    "    \n",
    "    matched_remainder_amended_df = pd.concat([matched_remainder_amended_df_t, matched_remainder_amended_df_f])\n",
    "    unit_sizes_appendix = ready_costing[['Food Item (As per POS system)', 'Quantity']].copy()\n",
    "    unit_sizes_appendix.rename(columns = {'Food Item (As per POS system)': 'Product Name',\n",
    "                                          'Quantity': 'Unit Size'                                         \n",
    "                                         }, inplace = True)\n",
    "    unit_sizes = pd.concat([unit_sizes, unit_sizes_appendix])\n",
    "    matched_remainder_amended_df = matched_remainder_amended_df.merge(all_pos_cleaned[['Article', 'ID', 'Number of articles', 'Revenue']], left_on = 'Unmatched Article', right_on = 'Article')\n",
    "    matched_remainder_amended_df = matched_remainder_amended_df.merge(unit_sizes, how = 'left', left_on = 'Most Similar Stock In', right_on = 'Product Name')\n",
    "    matched_remainder_amended_df.drop(['Unmatched Article', 'Product Name'], axis = 1, inplace = True)\n",
    "\n",
    "    matched_remainder_amended_df = matched_remainder_amended_df.rename(columns = {\n",
    "        'Most Similar Stock In': 'Product Name',\n",
    "        'Subtotal': 'Est Total Cost',\n",
    "        'Article': 'Most Similar Article'\n",
    "    })\n",
    "\n",
    "    \n",
    "except:\n",
    "    matched_remainder_amended_df = matched_remainder_amended_df.merge(stock_in_drinks_expanded, left_on = \"Most Similar Stock In\", right_on = \"Product Name\")\n",
    "    matched_remainder_amended_df = matched_remainder_amended_df.merge(all_pos_cleaned[['Article', 'ID', 'Number of articles', 'Revenue']], left_on = 'Unmatched Article', right_on = 'Article')\n",
    "    matched_remainder_amended_df = matched_remainder_amended_df.merge(unit_sizes, how = 'left', left_on = 'Most Similar Stock In', right_on = 'Product Name')\n",
    "    matched_remainder_amended_df.drop(['Unmatched Article', 'Product Name_x', 'Product Name_y'], axis = 1, inplace = True)\n",
    "\n",
    "    matched_remainder_amended_df = matched_remainder_amended_df.rename(columns = {\n",
    "        'Most Similar Stock In': 'Product Name',\n",
    "        'Subtotal': 'Est Total Cost',\n",
    "        'Article': 'Most Similar Article'\n",
    "    })\n",
    "\n",
    "# rearrange columns\n",
    "matched_remainder_amended_df = matched_remainder_amended_df[['Product Name', 'Qty', 'Est Total Cost', 'Unit', 'Unit Size', 'Most Similar Article', 'ID', 'Number of articles', 'Revenue']].copy()\n",
    "matched_remainder_amended_df = matched_remainder_amended_df.drop_duplicates()\n",
    "\n",
    "# export\n",
    "matched_remainder_amended_df.to_csv(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\output\\jan22_reporting\\National\\Output\\Round 2\\unmatched_direct_match_amended_final.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4467d1d7",
   "metadata": {},
   "source": [
    "**Same Name but Different Unit Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3b3b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_in_narrow = stock_in.dropna(subset = ['Supplier Name'])\\\n",
    "    .loc[:,['Product Name', 'Unit']]\\\n",
    "    .copy()\\\n",
    "    .drop_duplicates()\n",
    "\n",
    "incorrect_duplicates = stock_in_narrow.groupby(['Product Name']).count()\n",
    "incorrect_duplicates = incorrect_duplicates.loc[incorrect_duplicates['Unit'] > 1,].copy()\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns = {'Unit': 'Count'})\n",
    "\n",
    "incorrect_stock_in = stock_in.merge(incorrect_duplicates, on = 'Product Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8108fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_name_different_unit_size(df):\n",
    "    df_narrow = df[['name', 'unitTypeId' , 'locationId']].copy()\\\n",
    "        .drop_duplicates()\n",
    "    \n",
    "    incorrect_duplicates = df_narrow.groupby(['name', 'locationId']).count()\n",
    "    incorrect_duplicates = incorrect_duplicates.loc[incorrect_duplicates['unitTypeId'] > 1, ].copy()\\\n",
    "        .reset_index()\\\n",
    "        .rename(columns = {'unitTypeId': 'count'})\n",
    "    \n",
    "    incorrect_duplicates = df.merge(incorrect_duplicates, on = ['name', 'locationId'])\n",
    "    \n",
    "    incorrect_duplicates_price_count = incorrect_duplicates[['locationId', 'name', 'unit_price']].copy()\n",
    "    incorrect_duplicates_price_count = incorrect_duplicates_price_count.groupby(['locationId', 'name']).nunique()\n",
    "    incorrect_duplicates_price_count = incorrect_duplicates_price_count.loc[incorrect_duplicates_price_count['unit_price'] > 1, ].copy().reset_index()\n",
    "    incorrect_duplicates_price_count = incorrect_duplicates_price_count.name.drop_duplicates().tolist()\n",
    "    \n",
    "    incorrect_duplicates = incorrect_duplicates.loc[incorrect_duplicates['name'].isin(incorrect_duplicates_price_count), ].copy()\n",
    "    \n",
    "    \n",
    "    return incorrect_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d73479c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config_fr\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "cnx = create_engine('postgresql://'+config_fr.USER+':'+config_fr.PASSWORD+'@'+config_fr.PGHOST+\":\"+config_fr.PORT+'/'+config_fr.PGDATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72505ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "expo_invoice_entity = pd.read_sql_query(\"\"\"\n",
    "SELECT  i.\"organizationId\", o.name AS organization_name, i.\"locationId\", \"invoiceId\", \"supplierId\", i.\"organizationProductId\", i.name, quantity, i.\"unitTypeId\", i.subtotal/i.quantity AS unit_price\n",
    "FROM invoice_product_entity AS i\n",
    "INNER JOIN location_entity AS l\n",
    "ON l.id = i.\"locationId\"\n",
    "INNER JOIN invoice_entity AS e\n",
    "ON i.\"invoiceId\" = e.id\n",
    "INNER JOIN organization_entity as o\n",
    "ON o.id = i.\"organizationId\"\n",
    "WHERE i.\"isDeleted\" = 'False'\n",
    "AND l.\"organizationId\" IN ('lrtbII54ZkE9HCTdeXJr', '2oHEmXUi0HnFo37pnaYI', 'qu988vwlSnCcL6R2chBx', 'kZ7a10fWDpM4BASHRK8v', 'imXyAwTlGaqc2sztrWHu')\n",
    "AND i.\"organizationId\" IN ('lrtbII54ZkE9HCTdeXJr', '2oHEmXUi0HnFo37pnaYI', 'qu988vwlSnCcL6R2chBx', 'kZ7a10fWDpM4BASHRK8v', 'imXyAwTlGaqc2sztrWHu')\n",
    "\"\"\", cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b63521a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expo_duplicated_names = same_name_different_unit_size(expo_invoice_entity)\n",
    "expo_duplicated_names.name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc9b8ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "expo_duplicated_names.to_csv(r'C:\\Users\\wesch\\Documents\\FoodRazor\\expo\\data\\Stock_In\\duplicated_names_error.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
